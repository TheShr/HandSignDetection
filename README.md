
âœ‹ **Hand Sign Detection using Deep Learning**

Welcome to HandSignDetection, a deep-learning based project designed to recognize hand gestures from live camera feed.
This system can be used for sign language recognition, gesture-based interaction, and accessibility tools.

ğŸš€ Features

âœ… Real-time hand sign detection

âœ… Trained CNN model for gesture classification

âœ… Dataset folders for custom training

âœ… Modular Jupyter Notebooks:

trainer.ipynb â†’ Train the model

main.ipynb â†’ Run prediction using webcam

âœ… .h5 trained model + .npy labels included

ğŸ§  **Model Overview**
Component	Description
Model Type	Convolutional Neural Network (CNN)
Framework	TensorFlow / Keras
Input	Hand gesture images
Output	Predicted sign label
Training	Limited dataset for prototype stage

The project currently supports limited signs due to early development.
You can expand the dataset to cover full A-Z & functional signs (space, delete, etc.)

ğŸ“¦ <br>**Installation**</br>
1ï¸âƒ£ Clone the repo
git clone https://github.com/TheShr/HandSignDetection.git
cd HandSignDetection

2ï¸âƒ£ Install dependencies
pip install tensorflow opencv-python numpy matplotlib


âœ¨ **Future Improvements**

Expand dataset to full sign language set

Use MediaPipe for better hand landmark extraction

Build Flask backend & web UI

Convert model into TensorFlow Lite for mobile apps

Add speech output for detected signs

ğŸ¯ Goal

This is a foundational sign language recognition model intended for:

Learning deep learning & image classification

Accessibility applications

Gesture-based UI systems

Future AI-driven assistive tech

ğŸ“š Credits

This project was developed to explore Computer Vision + Deep Learning applications in sign language understanding.

ğŸ› ï¸ Author

Anuj Sharma
B.Tech CSE, Bennett University

â­ Support


